# æ¨¡å‹ç®¡ç†æŒ‡å— ğŸ“¦

## âœ… å·²æ›´æ–°ï¼šæ¨¡å‹å­˜æ”¾åœ¨é¡¹ç›®å†…

æ‰€æœ‰æœ¬åœ°æ¨¡å‹ç°åœ¨å­˜æ”¾åœ¨ **`models/`** ç›®å½•ä¸­ï¼Œæ— éœ€åœ¨ç³»ç»Ÿå…¶ä»–ä½ç½®ä¸‹è½½ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
psychological_counseling_system/
â”œâ”€â”€ models/                          # âœ¨ æœ¬åœ°æ¨¡å‹ç›®å½•
â”‚   â”œâ”€â”€ README.md                   # æ¨¡å‹è¯´æ˜
â”‚   â””â”€â”€ tinyllama-*.gguf           # ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                # é…ç½®æ–‡ä»¶ (å·²æ›´æ–°è·¯å¾„)
â”œâ”€â”€ download_model.sh              # âœ¨ ä¸€é”®ä¸‹è½½è„šæœ¬
â””â”€â”€ ...
```

## ğŸš€ å¿«é€Ÿä¸‹è½½æ¨¡å‹

### æ–¹æ³•1: ä½¿ç”¨ä¸€é”®è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
cd psychological_counseling_system
./download_model.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
- âœ… é€‰æ‹©æœ€ä½³ä¸‹è½½å·¥å…·ï¼ˆwget/curlï¼‰
- âœ… æ˜¾ç¤ºä¸‹è½½è¿›åº¦
- âœ… éªŒè¯ä¸‹è½½ç»“æœ

### æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½

```bash
cd psychological_counseling_system/models

# ä½¿ç”¨wget
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# æˆ–ä½¿ç”¨curl
curl -L https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf -o tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

### æ–¹æ³•3: ä½¿ç”¨huggingface-cliï¼ˆæ¨èï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

```bash
# å®‰è£…huggingface-hub
pip install huggingface-hub

# ä¸‹è½½æ¨¡å‹
cd psychological_counseling_system/models
huggingface-cli download TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF \
  tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf \
  --local-dir . \
  --local-dir-use-symlinks False
```

## âš™ï¸ é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ `configs/config.yaml` å·²æ›´æ–°ï¼š

```yaml
llm:
  backend: 'local'
  local:
    model_path: './models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf'  # âœ… é¡¹ç›®å†…è·¯å¾„
    n_gpu_layers: 35  # ä½¿ç”¨GPUåŠ é€Ÿ
```

## ğŸ“Š æ¨¡å‹å¤§å°

- **TinyLlama-1.1B (Q4_K_M)**: ~600MB
- é¢„è®¡ä¸‹è½½æ—¶é—´: 1-5åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰

## ğŸ”„ åˆ‡æ¢æ¨¡å‹

å¦‚æœä½ æƒ³ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼š

### 1. ä¸‹è½½åˆ°modelsç›®å½•

```bash
cd psychological_counseling_system/models

# ä¾‹å¦‚: ä¸‹è½½Mistral-7B
huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF \
  mistral-7b-instruct-v0.2.Q4_K_M.gguf \
  --local-dir . \
  --local-dir-use-symlinks False
```

### 2. æ›´æ–°é…ç½®

```yaml
llm:
  local:
    model_path: './models/mistral-7b-instruct-v0.2.Q4_K_M.gguf'
```

## ğŸ“ æ¨èæ¨¡å‹åˆ—è¡¨

### é€‚åˆä½ çš„A40 GPU

| æ¨¡å‹ | å¤§å° | VRAMéœ€æ±‚ | æ¨èç”¨é€” |
|------|------|----------|---------|
| TinyLlama-1.1B | 0.6GB | ~2GB | å¿«é€Ÿæµ‹è¯• |
| Mistral-7B | 4.4GB | ~8GB | å¹³è¡¡æ€§èƒ½ |
| Llama-3-8B | 4.9GB | ~10GB | æ›´å¥½è´¨é‡ |
| Qwen2-7B | 4.5GB | ~9GB | ä¸­æ–‡ä¼˜åŒ– |

### ä¸‹è½½å‘½ä»¤å‚è€ƒ

```bash
# Mistral-7B
huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF \
  mistral-7b-instruct-v0.2.Q4_K_M.gguf --local-dir ./models --local-dir-use-symlinks False

# Llama-3-8B
huggingface-cli download QuantFactory/Meta-Llama-3-8B-Instruct-GGUF \
  Meta-Llama-3-8B-Instruct.Q4_K_M.gguf --local-dir ./models --local-dir-use-symlinks False

# Qwen2-7B (ä¸­æ–‡ä¼˜åŒ–)
huggingface-cli download Qwen/Qwen2-7B-Instruct-GGUF \
  qwen2-7b-instruct-q4_k_m.gguf --local-dir ./models --local-dir-use-symlinks False
```

## ğŸ—‘ï¸ ç®¡ç†æ¨¡å‹

### æŸ¥çœ‹å·²ä¸‹è½½çš„æ¨¡å‹

```bash
ls -lh models/*.gguf
```

### åˆ é™¤ä¸éœ€è¦çš„æ¨¡å‹

```bash
rm models/old_model.gguf
```

### æ¨¡å‹è¢«.gitignoreæ’é™¤

æ‰€æœ‰ `*.gguf` æ–‡ä»¶å·²è‡ªåŠ¨æ’é™¤åœ¨gitè¿½è¸ªä¹‹å¤–ï¼Œä¸ä¼šè¢«æäº¤åˆ°ä»“åº“ã€‚

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸‹è½½é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ1**: ä½¿ç”¨å›½å†…é•œåƒ
```bash
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download ...
```

**æ–¹æ¡ˆ2**: ä½¿ç”¨ä»£ç†
```bash
export https_proxy=http://your-proxy:port
wget ...
```

### Q2: ä¸‹è½½ä¸­æ–­æ€ä¹ˆåŠï¼Ÿ

ä½¿ç”¨ `huggingface-cli` æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼š
```bash
huggingface-cli download ... --resume-download
```

æˆ–ä½¿ç”¨ `wget` çš„ `-c` å‚æ•°ï¼š
```bash
wget -c https://...
```

### Q3: å¦‚ä½•éªŒè¯æ¨¡å‹å®Œæ•´æ€§ï¼Ÿ

```bash
# æ£€æŸ¥æ–‡ä»¶å¤§å°
ls -lh models/*.gguf

# TinyLlamaåº”è¯¥çº¦600MB
# å¦‚æœå¤§å°ä¸å¯¹ï¼Œé‡æ–°ä¸‹è½½
```

## ğŸ¯ ä¼˜ç‚¹æ€»ç»“

âœ… **ä¾¿äºç®¡ç†**: æ‰€æœ‰æ¨¡å‹åœ¨é¡¹ç›®å†…ï¼Œæ¸…æ™°å¯è§  
âœ… **æ˜“äºè¿ç§»**: å¤åˆ¶æ•´ä¸ªé¡¹ç›®å³å¯è¿ç§»  
âœ… **ä¸æ±¡æŸ“ç³»ç»Ÿ**: ä¸åœ¨ç³»ç»Ÿå…¶ä»–ä½ç½®å­˜æ”¾å¤§æ–‡ä»¶  
âœ… **è‡ªåŠ¨å¿½ç•¥**: gitä¼šè‡ªåŠ¨å¿½ç•¥æ¨¡å‹æ–‡ä»¶  
âœ… **å›¢é˜Ÿåä½œ**: æ¯ä¸ªå¼€å‘è€…ç®¡ç†è‡ªå·±çš„æ¨¡å‹  

---

**éœ€è¦å¸®åŠ©?** æŸ¥çœ‹ `models/README.md` è·å–æ›´å¤šä¿¡æ¯ã€‚
