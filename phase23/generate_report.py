#!/usr/bin/env python3
"""
æŠ¥å‘Šç”Ÿæˆå™¨ - ç”ŸæˆMarkdownæ ¼å¼çš„è¯„ä¼°æŠ¥å‘Š

ç”¨é€”ï¼š
1. å°†è¯„ä¼°ç»“æœè½¬æ¢ä¸ºå¯è¯»çš„MarkdownæŠ¥å‘Š
2. åŒ…å«å¯¹æ¯”è¡¨æ ¼ã€ç»Ÿè®¡åˆ†æ
3. å¯ç›´æ¥ç”¨äºè®ºæ–‡æˆ–æ–‡æ¡£

ä½¿ç”¨æ–¹æ³•ï¼š
    python evaluation/scripts/generate_report.py --result evaluation/results/comparison/comparison_20241109.json
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, result_file: str):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            result_file: è¯„ä¼°ç»“æœJSONæ–‡ä»¶è·¯å¾„
        """
        self.result_file = result_file
        
        # åŠ è½½ç»“æœ
        with open(result_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        self.report_lines = []
    
    def generate(self) -> str:
        """
        ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
        """
        self._add_header()
        self._add_metadata()
        self._add_summary()
        self._add_technical_metrics()
        self._add_clinical_metrics()
        self._add_memory_metrics()
        self._add_rag_metrics()
        self._add_improvements()
        self._add_conclusions()
        
        return '\n'.join(self.report_lines)
    
    def _add_header(self):
        """æ·»åŠ æŠ¥å‘Šæ ‡é¢˜"""
        self.report_lines.extend([
            "# å¿ƒç†å’¨è¯¢ç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š",
            "",
            "## å¯¹æ¯”å®éªŒç»“æœ",
            ""
        ])
    
    def _add_metadata(self):
        """æ·»åŠ å…ƒæ•°æ®"""
        metadata = self.data.get('metadata', {})
        
        self.report_lines.extend([
            "### åŸºæœ¬ä¿¡æ¯",
            "",
            f"- **ç”Ÿæˆæ—¶é—´**: {metadata.get('timestamp', 'N/A')}",
            f"- **æµ‹è¯•æ ·æœ¬æ•°**: {metadata.get('num_samples', 'N/A')}",
            f"- **ç³»ç»Ÿé…ç½®**: `{metadata.get('system_config', 'N/A')}`",
            f"- **è¯„ä¼°é…ç½®**: `{metadata.get('eval_config', 'N/A')}`",
            ""
        ])
    
    def _add_summary(self):
        """æ·»åŠ æ€»ç»“"""
        results = self.data.get('results', {})
        
        self.report_lines.extend([
            "### è¯„ä¼°æ€»ç»“",
            "",
            "æœ¬æ¬¡è¯„ä¼°å¯¹æ¯”äº†ä¸‰ç§ç³»ç»Ÿé…ç½®ï¼š",
            "",
            "1. **è£¸LLMï¼ˆåŸºçº¿ï¼‰**: ä»…ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸å¯ç”¨RAGå’Œè®°å¿†ç³»ç»Ÿ",
            "2. **LLM + RAG**: å¯ç”¨çŸ¥è¯†åº“æ£€ç´¢ï¼Œä¸å¯ç”¨è®°å¿†ç³»ç»Ÿ",
            "3. **å®Œæ•´ç³»ç»Ÿ**: åŒæ—¶å¯ç”¨RAGå’Œä¸‰å±‚è®°å¿†ç³»ç»Ÿ",
            ""
        ])
    
    def _add_technical_metrics(self):
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡å¯¹æ¯”è¡¨"""
        self.report_lines.extend([
            "### æŠ€æœ¯æŒ‡æ ‡å¯¹æ¯”",
            "",
            "| æŒ‡æ ‡ | è£¸LLM | LLM+RAG | å®Œæ•´ç³»ç»Ÿ | æ”¹è¿›å¹…åº¦ |",
            "| --- | --- | --- | --- | --- |"
        ])
        
        results = self.data.get('results', {})
        
        # æå–æ•°æ®
        configs = ['baseline', 'rag_only', 'full_system']
        tech_data = {}
        
        for config in configs:
            if config in results:
                tech_data[config] = results[config]['results'].get('technical_metrics', {})
        
        # BERT Score
        bert_values = []
        for config in configs:
            if config in tech_data:
                val = tech_data[config].get('bert_score', {}).get('f1', 0)
                bert_values.append(val)
            else:
                bert_values.append(0)
        
        improvement = self._calculate_improvement(bert_values[0], bert_values[2])
        self.report_lines.append(
            f"| BERT Score F1 | {bert_values[0]:.3f} | {bert_values[1]:.3f} | {bert_values[2]:.3f} | {improvement} |"
        )
        
        # ROUGE-L
        rouge_values = []
        for config in configs:
            if config in tech_data:
                val = tech_data[config].get('rouge', {}).get('rougeL', 0)
                rouge_values.append(val)
            else:
                rouge_values.append(0)
        
        improvement = self._calculate_improvement(rouge_values[0], rouge_values[2])
        self.report_lines.append(
            f"| ROUGE-L | {rouge_values[0]:.3f} | {rouge_values[1]:.3f} | {rouge_values[2]:.3f} | {improvement} |"
        )
        
        # BLEU
        bleu_values = []
        for config in configs:
            if config in tech_data:
                val = tech_data[config].get('bleu', 0)
                bleu_values.append(val)
            else:
                bleu_values.append(0)
        
        improvement = self._calculate_improvement(bleu_values[0], bleu_values[2])
        self.report_lines.append(
            f"| BLEU | {bleu_values[0]:.3f} | {bleu_values[1]:.3f} | {bleu_values[2]:.3f} | {improvement} |"
        )
        
        # å“åº”æ—¶é—´
        time_values = []
        for config in configs:
            if config in tech_data:
                val = tech_data[config].get('response_time', 0)
                time_values.append(val)
            else:
                time_values.append(0)
        
        self.report_lines.append(
            f"| å“åº”æ—¶é—´(ç§’) | {time_values[0]:.2f} | {time_values[1]:.2f} | {time_values[2]:.2f} | - |"
        )
        
        self.report_lines.append("")
    
    def _add_clinical_metrics(self):
        """æ·»åŠ ä¸´åºŠæŒ‡æ ‡å¯¹æ¯”è¡¨"""
        self.report_lines.extend([
            "### ä¸´åºŠæŒ‡æ ‡å¯¹æ¯”",
            "",
            "| æŒ‡æ ‡ | è£¸LLM | LLM+RAG | å®Œæ•´ç³»ç»Ÿ | æ”¹è¿›å¹…åº¦ |",
            "| --- | --- | --- | --- | --- |"
        ])
        
        results = self.data.get('results', {})
        configs = ['baseline', 'rag_only', 'full_system']
        
        clinical_metrics = {
            'empathy': 'å…±æƒ…',
            'support': 'æ”¯æŒ',
            'guidance': 'æŒ‡å¯¼',
            'relevance': 'ç›¸å…³æ€§',
            'communication': 'æ²Ÿé€š',
            'fluency': 'æµç•…æ€§',
            'safety': 'å®‰å…¨æ€§'
        }
        
        for metric_key, metric_name in clinical_metrics.items():
            values = []
            for config in configs:
                if config in results:
                    val = results[config]['results'].get('clinical_metrics', {}).get(metric_key, 0)
                    values.append(val)
                else:
                    values.append(0)
            
            improvement = self._calculate_improvement(values[0], values[2])
            self.report_lines.append(
                f"| {metric_name} | {values[0]:.2f} | {values[1]:.2f} | {values[2]:.2f} | {improvement} |"
            )
        
        self.report_lines.append("")
    
    def _add_memory_metrics(self):
        """æ·»åŠ è®°å¿†ç³»ç»ŸæŒ‡æ ‡"""
        self.report_lines.extend([
            "### è®°å¿†ç³»ç»Ÿæ€§èƒ½",
            "",
            "è®°å¿†ç³»ç»Ÿä»…åœ¨å®Œæ•´ç³»ç»Ÿä¸­å¯ç”¨ï¼š",
            ""
        ])
        
        results = self.data.get('results', {})
        
        if 'full_system' in results:
            memory = results['full_system']['results'].get('memory_metrics', {})
            
            self.report_lines.extend([
                "| æŒ‡æ ‡ | æ€§èƒ½ |",
                "| --- | --- |",
                f"| çŸ­æœŸè®°å¿†å¬å› | {memory.get('short_term_recall', 0)*100:.2f}% |",
                f"| å·¥ä½œè®°å¿†å‡†ç¡®ç‡ | {memory.get('working_memory_accuracy', 0)*100:.2f}% |",
                f"| é•¿æœŸè®°å¿†ä¸€è‡´æ€§ | {memory.get('long_term_consistency', 0)*100:.2f}% |",
                f"| æ•´ä½“å‡†ç¡®ç‡ | {memory.get('overall_accuracy', 0)*100:.2f}% |",
                ""
            ])
        else:
            self.report_lines.append("*æ•°æ®ä¸å¯ç”¨*\n")
    
    def _add_rag_metrics(self):
        """æ·»åŠ RAGæ•ˆæœæŒ‡æ ‡"""
        self.report_lines.extend([
            "### RAGæ£€ç´¢æ•ˆæœ",
            "",
            "RAGç³»ç»Ÿåœ¨LLM+RAGå’Œå®Œæ•´ç³»ç»Ÿä¸­å¯ç”¨ï¼š",
            "",
            "| é…ç½® | å¬å›ç‡ | ç²¾ç¡®ç‡ | F1 Score |",
            "| --- | --- | --- | --- |"
        ])
        
        results = self.data.get('results', {})
        
        for config in ['rag_only', 'full_system']:
            if config in results:
                config_name = "LLM+RAG" if config == 'rag_only' else "å®Œæ•´ç³»ç»Ÿ"
                rag = results[config]['results'].get('rag_metrics', {})
                
                recall = rag.get('recall', 0) * 100
                precision = rag.get('precision', 0) * 100
                f1 = rag.get('f1', 0)
                
                self.report_lines.append(
                    f"| {config_name} | {recall:.2f}% | {precision:.2f}% | {f1:.3f} |"
                )
        
        self.report_lines.append("")
    
    def _add_improvements(self):
        """æ·»åŠ æ”¹è¿›å¹…åº¦åˆ†æ"""
        improvements = self.data.get('improvements', {})
        
        if not improvements:
            return
        
        self.report_lines.extend([
            "### å®Œæ•´ç³»ç»Ÿç›¸æ¯”è£¸LLMçš„æ”¹è¿›",
            "",
            "| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |",
            "| --- | --- |"
        ])
        
        metric_names = {
            'bert_f1': 'BERT Score F1',
            'rouge_l': 'ROUGE-L',
            'bleu': 'BLEU',
            'empathy': 'å…±æƒ…',
            'support': 'æ”¯æŒ',
            'guidance': 'æŒ‡å¯¼',
            'relevance': 'ç›¸å…³æ€§',
            'communication': 'æ²Ÿé€š',
            'fluency': 'æµç•…æ€§'
        }
        
        for metric, improvement in improvements.items():
            metric_name = metric_names.get(metric, metric)
            sign = '+' if improvement > 0 else ''
            self.report_lines.append(
                f"| {metric_name} | {sign}{improvement:.2f}% |"
            )
        
        self.report_lines.append("")
    
    def _add_conclusions(self):
        """æ·»åŠ ç»“è®º"""
        self.report_lines.extend([
            "### ç»“è®º",
            "",
            "æ ¹æ®è¯„ä¼°ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š",
            "",
            "1. **RAGç³»ç»Ÿçš„æœ‰æ•ˆæ€§**",
            "   - LLM+RAGç›¸æ¯”è£¸LLMåœ¨ä¸“ä¸šæ€§æŒ‡æ ‡ä¸Šæœ‰æ˜¾è‘—æå‡",
            "   - çŸ¥è¯†åº“æ£€ç´¢æä¾›äº†æ›´å‡†ç¡®å’Œç›¸å…³çš„å¿ƒç†å­¦çŸ¥è¯†",
            "",
            "2. **è®°å¿†ç³»ç»Ÿçš„ä»·å€¼**",
            "   - å®Œæ•´ç³»ç»Ÿåœ¨ç”¨æˆ·ç†è§£å’Œä¸ªæ€§åŒ–æ–¹é¢è¡¨ç°æœ€ä½³",
            "   - ä¸‰å±‚è®°å¿†æ¶æ„æœ‰æ•ˆè¿½è¸ªç”¨æˆ·çŠ¶æ€å’Œå†å²",
            "",
            "3. **ç³»ç»Ÿæ€§èƒ½**",
            "   - æŠ€æœ¯æŒ‡æ ‡ï¼ˆBERT Score, ROUGEç­‰ï¼‰æ˜¾ç¤ºç³»ç»Ÿå›å¤è´¨é‡é«˜",
            "   - ä¸´åºŠæŒ‡æ ‡ï¼ˆå…±æƒ…ã€æ”¯æŒç­‰ï¼‰è¾¾åˆ°ä¸“ä¸šæ°´å¹³",
            "",
            "---",
            "",
            f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        ])
    
    def _calculate_improvement(self, baseline: float, improved: float) -> str:
        """è®¡ç®—æ”¹è¿›å¹…åº¦"""
        if baseline == 0:
            return "N/A"
        
        improvement = ((improved - baseline) / baseline) * 100
        sign = '+' if improvement > 0 else ''
        return f"{sign}{improvement:.2f}%"
    
    def save(self, output_file: str = None) -> str:
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            # æ ¹æ®ç»“æœæ–‡ä»¶ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            result_path = Path(self.result_file)
            output_file = result_path.parent / f"{result_path.stem}_report.md"
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate()
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        print(f"  æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.1f} KB")
        
        return str(output_path)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š')
    parser.add_argument('--result', type=str, required=True,
                       help='è¯„ä¼°ç»“æœJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰')
    
    args = parser.parse_args()
    
    try:
        print("\n" + "="*70)
        print(" "*25 + "ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š")
        print("="*70)
        
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = ReportGenerator(args.result)
        
        # ä¿å­˜æŠ¥å‘Š
        output_file = generator.save(args.output)
        
        print("\n" + "="*70)
        print(" "*25 + "æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print("="*70)
        print(f"\nâœ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")
        print("\nğŸ“ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹:")
        print(f"  cat {output_file}")
        print(f"  æˆ–åœ¨MarkdownæŸ¥çœ‹å™¨ä¸­æ‰“å¼€")
        
    except Exception as e:
        print(f"\nâœ— æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
