{
  "metadata": {
    "timestamp": "20251109_123722",
    "num_samples": 50,
    "system_config": "configs/config.yaml",
    "eval_config": "evaluation/configs/default_config.yaml"
  },
  "results": {
    "baseline": {
      "config_desc": "裸LLM（基线）",
      "results": {
        "evaluation_time": "2025-11-09T12:32:54.617348",
        "test_data_info": {
          "num_questions": 1,
          "clinical_sample_size": 50
        },
        "technical_metrics": {
          "bert_precision": 0.7560367584228516,
          "bert_recall": 0.7524018287658691,
          "bert_f1": 0.754214882850647,
          "rouge1_f1": 0.555045871559633,
          "rouge2_f1": 0.17471264367816094,
          "rougeL_f1": 0.2110091743119266,
          "bleu": 0.5418394692318115,
          "avg_length": 3136.0,
          "min_length": 3136.0,
          "max_length": 3136.0,
          "std_length": 0.0
        },
        "clinical_metrics": {
          "empathy_avg": 0.0,
          "empathy_std": 0.0,
          "supportiveness_avg": 0.0,
          "supportiveness_std": 0.0,
          "guidance_avg": 0.0,
          "guidance_std": 0.0,
          "reflectiveness_avg": 0.0,
          "reflectiveness_std": 0.0,
          "reassurance_avg": 0.0,
          "reassurance_std": 0.0,
          "professionalism_avg": 0.0,
          "professionalism_std": 0.0,
          "information_avg": 0.0,
          "information_std": 0.0,
          "overall_avg": 0.0
        },
        "overall_score": 0.3771074414253235
      },
      "elapsed_time": 93.7363383769989
    },
    "rag_only": {
      "config_desc": "LLM + RAG",
      "results": {
        "evaluation_time": "2025-11-09T12:34:27.268581",
        "test_data_info": {
          "num_questions": 1,
          "clinical_sample_size": 50
        },
        "technical_metrics": {
          "bert_precision": 0.7560367584228516,
          "bert_recall": 0.7524018287658691,
          "bert_f1": 0.754214882850647,
          "rouge1_f1": 0.555045871559633,
          "rouge2_f1": 0.17471264367816094,
          "rougeL_f1": 0.2110091743119266,
          "bleu": 0.5418394692318115,
          "avg_length": 3136.0,
          "min_length": 3136.0,
          "max_length": 3136.0,
          "std_length": 0.0
        },
        "clinical_metrics": {
          "empathy_avg": 0.0,
          "empathy_std": 0.0,
          "supportiveness_avg": 0.0,
          "supportiveness_std": 0.0,
          "guidance_avg": 0.0,
          "guidance_std": 0.0,
          "reflectiveness_avg": 0.0,
          "reflectiveness_std": 0.0,
          "reassurance_avg": 0.0,
          "reassurance_std": 0.0,
          "professionalism_avg": 0.0,
          "professionalism_std": 0.0,
          "information_avg": 0.0,
          "information_std": 0.0,
          "overall_avg": 0.0
        },
        "overall_score": 0.3771074414253235
      },
      "elapsed_time": 98.59268307685852
    },
    "full_system": {
      "config_desc": "完整系统（LLM + RAG + 记忆）",
      "results": {
        "evaluation_time": "2025-11-09T12:36:08.436863",
        "test_data_info": {
          "num_questions": 1,
          "clinical_sample_size": 50
        },
        "technical_metrics": {
          "bert_precision": 0.7560367584228516,
          "bert_recall": 0.7524018287658691,
          "bert_f1": 0.754214882850647,
          "rouge1_f1": 0.555045871559633,
          "rouge2_f1": 0.17471264367816094,
          "rougeL_f1": 0.2110091743119266,
          "bleu": 0.5418394692318115,
          "avg_length": 3136.0,
          "min_length": 3136.0,
          "max_length": 3136.0,
          "std_length": 0.0
        },
        "clinical_metrics": {
          "empathy_avg": 0.0,
          "empathy_std": 0.0,
          "supportiveness_avg": 0.0,
          "supportiveness_std": 0.0,
          "guidance_avg": 0.0,
          "guidance_std": 0.0,
          "reflectiveness_avg": 0.0,
          "reflectiveness_std": 0.0,
          "reassurance_avg": 0.0,
          "reassurance_std": 0.0,
          "professionalism_avg": 0.0,
          "professionalism_std": 0.0,
          "information_avg": 0.0,
          "information_std": 0.0,
          "overall_avg": 0.0
        },
        "overall_score": 0.3771074414253235
      },
      "elapsed_time": 94.32375574111938
    }
  },
  "improvements": {}
}