# å®‰è£…å’Œéƒ¨ç½²æŒ‡å—

## é¡¹ç›®å·²å®Œæˆï¼ğŸ‰

ä½ çš„å¿ƒç†å’¨è¯¢ç³»ç»Ÿä»£ç ä»“åº“å·²ç»å®Œå…¨æ„å»ºå®Œæˆã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„éƒ¨ç½²å’Œä½¿ç”¨æŒ‡å—ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
psychological_counseling_system/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ llm/                            # LLMæŠ½è±¡å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                     # åŸºç±»
â”‚   â”œâ”€â”€ openai_llm.py              # OpenAIå®ç°
â”‚   â”œâ”€â”€ local_llm.py               # æœ¬åœ°GGUFæ¨¡å‹å®ç°
â”‚   â””â”€â”€ factory.py                  # å·¥å‚ç±»
â”œâ”€â”€ knowledge/                      # çŸ¥è¯†åº“æ¨¡å—(RAG)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                     # åŸºç±»
â”‚   â”œâ”€â”€ chroma_kb.py               # ChromaDBå®ç°
â”‚   â””â”€â”€ rag_manager.py             # RAGç®¡ç†å™¨
â”œâ”€â”€ memory/                         # è®°å¿†ç³»ç»Ÿæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                   # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ storage.py                  # å­˜å‚¨åç«¯
â”‚   â””â”€â”€ manager.py                  # è®°å¿†ç®¡ç†å™¨
â”œâ”€â”€ dialogue/                       # å¯¹è¯ç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ manager.py                  # å¯¹è¯ç®¡ç†å™¨(æ•´åˆæ‰€æœ‰ç»„ä»¶)
â”œâ”€â”€ utils/                          # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ examples/                       # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ basic_rag_chat.py          # åŸºç¡€å¯¹è¯ç¤ºä¾‹
â”‚   â””â”€â”€ multi_session_chat.py      # å¤šä¼šè¯ç¤ºä¾‹
â”œâ”€â”€ tests/                          # æµ‹è¯•ä»£ç 
â”‚   â””â”€â”€ test_system.py             # ç³»ç»Ÿæµ‹è¯•
â”œâ”€â”€ docs/                           # æ–‡æ¡£
â”‚   â””â”€â”€ quickstart.md              # å¿«é€Ÿå…¥é—¨
â”œâ”€â”€ data/                           # æ•°æ®ç›®å½•(è‡ªåŠ¨åˆ›å»º)
â”œâ”€â”€ logs/                           # æ—¥å¿—ç›®å½•(è‡ªåŠ¨åˆ›å»º)
â”œâ”€â”€ requirements.txt                # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ .env.template                   # ç¯å¢ƒå˜é‡æ¨¡æ¿
â””â”€â”€ README.md                       # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸Šä¼ åˆ°æœåŠ¡å™¨

å°†æ•´ä¸ª `psychological_counseling_system` ç›®å½•ä¸Šä¼ åˆ°ä½ çš„æœåŠ¡å™¨ï¼š

```bash
# åœ¨ä½ çš„æœ¬åœ°æœºå™¨
scp -r psychological_counseling_system root@your-server:/path/to/project/

# æˆ–ä½¿ç”¨ä½ å–œæ¬¢çš„æ–¹å¼ï¼ˆå¦‚git, rsyncç­‰ï¼‰
```

### 2. å®‰è£…ä¾èµ–

åœ¨æœåŠ¡å™¨ä¸Šï¼š

```bash
# æ¿€æ´»condaç¯å¢ƒ
conda activate psy_counsel  # æˆ–åˆ›å»ºæ–°ç¯å¢ƒ

# è¿›å…¥é¡¹ç›®ç›®å½•
cd psychological_counseling_system

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 3. é…ç½®ç³»ç»Ÿ

#### æ–¹æ¡ˆA: ä½¿ç”¨OpenAI APIï¼ˆæ¨èç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰

```bash
# 1. å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.template .env

# 2. ç¼–è¾‘.envæ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„APIå¯†é’¥
nano .env
# åœ¨æ–‡ä»¶ä¸­æ·»åŠ :
# OPENAI_API_KEY=sk-your-api-key-here

# 3. ç¼–è¾‘é…ç½®æ–‡ä»¶
nano configs/config.yaml
# ç¡®ä¿ä»¥ä¸‹é…ç½®:
# llm:
#   backend: 'api'
#   api:
#     provider: 'openai'
#     model: 'gpt-4o-mini'
```

#### æ–¹æ¡ˆB: ä½¿ç”¨æœ¬åœ°TinyLlamaæ¨¡å‹

```bash
# 1. ä¸‹è½½æ¨¡å‹åˆ°é¡¹ç›®å†…çš„modelsç›®å½•
cd psychological_counseling_system/models

# æ–¹æ³•1: ä½¿ç”¨wget
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# æ–¹æ³•2: ä½¿ç”¨huggingface-cliï¼ˆæ¨èï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
pip install huggingface-hub
huggingface-cli download TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF \
  tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf \
  --local-dir . \
  --local-dir-use-symlinks False

# 2. è¿”å›é¡¹ç›®æ ¹ç›®å½•å¹¶ç¼–è¾‘é…ç½®
cd ..
nano configs/config.yaml
# ä¿®æ”¹:
# llm:
#   backend: 'local'
#   local:
#     model_path: './models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf'
#     n_gpu_layers: 35  # åˆ©ç”¨ä½ çš„A40 GPU
```

### 4. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œç³»ç»Ÿæµ‹è¯•
python tests/test_system.py
```

å¦‚æœçœ‹åˆ°æ‰€æœ‰æµ‹è¯•éƒ½æ˜¯ âœ… PASSEDï¼Œè¯´æ˜ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼

### 5. è¿è¡Œç¤ºä¾‹

```bash
# åŸºç¡€å¯¹è¯ç¤ºä¾‹
python examples/basic_rag_chat.py

# å¤šä¼šè¯å¯¹è¯ç¤ºä¾‹ï¼ˆå±•ç¤ºè®°å¿†ç³»ç»Ÿï¼‰
python examples/multi_session_chat.py
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½å±•ç¤º

### åŠŸèƒ½1: RAGå¢å¼ºçš„å¯¹è¯

ç³»ç»Ÿä¼šè‡ªåŠ¨ä»å¿ƒç†çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼š

```python
from dialogue import create_dialogue_manager_from_config
from utils import load_config

config = load_config()
dm = create_dialogue_manager_from_config(config)

# æ·»åŠ å¿ƒç†çŸ¥è¯†
from knowledge import Document
dm.rag_manager.add_psychological_knowledge([
    Document(
        content="è®¤çŸ¥è¡Œä¸ºç–—æ³•(CBT)é€šè¿‡æ”¹å˜æ€ç»´æ¨¡å¼æ¥æ”¹å–„æƒ…ç»ª...",
        metadata={"source": "CBTåŸºç¡€"}
    )
])

# ç”¨æˆ·é—®é¢˜ä¼šè‡ªåŠ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†
response = dm.chat(user_id, session_id, "ä»€ä¹ˆæ˜¯CBT?")
```

### åŠŸèƒ½2: ä¸‰å±‚è®°å¿†ç³»ç»Ÿ

- **ä¼šè¯çº§è®°å¿†**ï¼šè®°ä½å½“å‰å¯¹è¯çš„æ‰€æœ‰å†…å®¹
- **ç”¨æˆ·æ¡£æ¡ˆ**ï¼šå­˜å‚¨ç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯å’Œä¸»è¦é—®é¢˜
- **é•¿æœŸè¶‹åŠ¿**ï¼šè¿½è¸ªæƒ…ç»ªå˜åŒ–ã€è¯é¢˜æ¼”å˜

```python
# ç¬¬ä¸€æ¬¡ä¼šè¯
session1_id = dm.start_session("user001")
dm.chat("user001", session1_id, "æˆ‘æœ€è¿‘å‹åŠ›å¾ˆå¤§")
dm.end_session("user001", session1_id)

# ç¬¬äºŒæ¬¡ä¼šè¯ï¼ˆå‡ å¤©åï¼‰
session2_id = dm.start_session("user001")
# ç³»ç»Ÿä¼šè®°ä½ç¬¬ä¸€æ¬¡ä¼šè¯çš„å†…å®¹ï¼
dm.chat("user001", session2_id, "ä¸Šæ¬¡è¯´çš„å‹åŠ›é—®é¢˜...")
```

### åŠŸèƒ½3: è‡ªåŠ¨ä¼šè¯æ‘˜è¦

æ¯æ¬¡ä¼šè¯ç»“æŸæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
1. ç”Ÿæˆä¼šè¯æ‘˜è¦
2. æå–ä¸»è¦è¯é¢˜
3. è®°å½•æƒ…ç»ªè½¨è¿¹

## ğŸ”§ è‡ªå®šä¹‰å’Œæ‰©å±•

### æ·»åŠ æ–°çš„LLMåç«¯

```python
# 1. åˆ›å»ºæ–°çš„LLMç±»
from llm.base import BaseLLM

class CustomLLM(BaseLLM):
    def generate(self, messages, **kwargs):
        # ä½ çš„å®ç°
        pass
    
    def count_tokens(self, text):
        # ä½ çš„å®ç°
        pass

# 2. æ³¨å†Œ
from llm import LLMFactory
LLMFactory.register('custom', CustomLLM)

# 3. åœ¨é…ç½®ä¸­ä½¿ç”¨
# config.yaml:
# llm:
#   backend: 'custom'
#   custom:
#     your_params: ...
```

### æ·»åŠ æ–°çš„çŸ¥è¯†åº“

```python
from knowledge.base import BaseKnowledgeBase

class MyKnowledgeBase(BaseKnowledgeBase):
    # å®ç°å¿…éœ€çš„æ–¹æ³•
    pass

# ä½¿ç”¨
my_kb = MyKnowledgeBase(config)
rag_manager = RAGManager(
    psychological_kb=my_kb,
    user_kb=user_kb,
    config=config
)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### é’ˆå¯¹ä½ çš„A40 GPU

```yaml
# configs/config.yaml
rag:
  embedding:
    device: 'cuda'  # ä½¿ç”¨GPU

llm:
  local:
    n_gpu_layers: 35  # å…¨éƒ¨å±‚ä½¿ç”¨GPU
```

### æ‰¹é‡å¤„ç†

å¦‚æœéœ€è¦å¤„ç†å¤šä¸ªç”¨æˆ·ï¼š

```python
# ä½¿ç”¨çº¿ç¨‹æ± æˆ–è¿›ç¨‹æ± 
from concurrent.futures import ThreadPoolExecutor

def process_user(user_id, message):
    session_id = dm.start_session(user_id)
    response = dm.chat(user_id, session_id, message)
    dm.end_session(user_id, session_id)
    return response

with ThreadPoolExecutor(max_workers=4) as executor:
    results = executor.map(process_user, user_ids, messages)
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å‡å°‘GPUå±‚æ•°
llm:
  local:
    n_gpu_layers: 20  # ä»35é™åˆ°20
```

æˆ–ä½¿ç”¨CPUï¼š
```yaml
rag:
  embedding:
    device: 'cpu'
```

### Q2: ChromaDBæŠ¥é”™

**è§£å†³æ–¹æ¡ˆ**:
```bash
# åˆ é™¤æ—§çš„å‘é‡æ•°æ®åº“
rm -rf data/vector_db
# é‡æ–°è¿è¡Œ
```

### Q3: APIè°ƒç”¨è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¢åŠ è¶…æ—¶æ—¶é—´
import openai
openai.api_timeout = 60  # ç§’
```

## ğŸ“ ä¸‹ä¸€æ­¥å¼€å‘è®¡åˆ’

å·²å®Œæˆï¼š
- [x] Phase 1: åŸºç¡€RAGæ¡†æ¶
- [x] Phase 2: è®°å¿†ç³»ç»Ÿ

å³å°†å¼€å‘ï¼š
- [ ] Phase 3: å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«
  - è¯­éŸ³æƒ…æ„Ÿåˆ†æ
  - é¢éƒ¨è¡¨æƒ…è¯†åˆ«
  - è·¨æ¨¡æ€èåˆ
- [ ] Phase 4: å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**: `logs/system.log`
2. **è¿è¡Œæµ‹è¯•**: `python tests/test_system.py`
3. **æŸ¥çœ‹æ–‡æ¡£**: `docs/quickstart.md`

## ğŸ“ è®ºæ–‡å†™ä½œå»ºè®®

### å®éªŒæ•°æ®æ”¶é›†

ç³»ç»Ÿå·²ç»å†…ç½®äº†å®Œæ•´çš„æ—¥å¿—å’Œæ•°æ®è®°å½•ï¼š

```python
# è®°å¿†æ•°æ®å­˜å‚¨åœ¨
data/memory_db/user_xxx.json

# å¯ä»¥ç”¨äºåˆ†æ:
# - å¯¹è¯è½®æ¬¡
# - ä¼šè¯æ‘˜è¦è´¨é‡
# - æƒ…ç»ªå˜åŒ–è¶‹åŠ¿
# - RAGæ£€ç´¢æ•ˆæœ
```

### è¯„ä¼°æŒ‡æ ‡

å»ºè®®çš„è¯„ä¼°ç»´åº¦ï¼š

1. **è®°å¿†å‡†ç¡®æ€§**: ç³»ç»Ÿèƒ½å¦æ­£ç¡®å¼•ç”¨å†å²ä¿¡æ¯
2. **RAGç›¸å…³æ€§**: æ£€ç´¢çš„çŸ¥è¯†æ˜¯å¦ç›¸å…³
3. **ç”¨æˆ·æ»¡æ„åº¦**: ä¸»è§‚è¯„åˆ†
4. **å¯¹è¯è¿è´¯æ€§**: å¤šè½®å¯¹è¯çš„è¿è´¯æ€§

### å¯¹æ¯”å®éªŒ

```python
# Baseline 1: æ— è®°å¿†çš„RAG
config['dialogue']['generation']['enable_memory'] = False

# Baseline 2: æ— RAGçš„å¯¹è¯
config['dialogue']['generation']['enable_rag'] = False

# ä½ çš„ç³»ç»Ÿ: å®Œæ•´åŠŸèƒ½
# å¯¹æ¯”ä¸‰ç§é…ç½®çš„æ•ˆæœ
```

## ğŸ‰ æ­å–œï¼

ä½ ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªï¼š
- âœ… é«˜åº¦æ¨¡å—åŒ–çš„ä»£ç åº“
- âœ… æ”¯æŒå¢é‡å¼€å‘
- âœ… æ˜“äºæ‰©å±•å’Œç»´æŠ¤
- âœ… å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹
- âœ… Phase 1 & 2 åŠŸèƒ½å®Œæ•´å®ç°

å‡†å¤‡å¥½å¼€å§‹ä½ çš„å®éªŒäº†å—ï¼Ÿç¥ä½ è®ºæ–‡é¡ºåˆ©ï¼ğŸš€
