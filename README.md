# Psychological Counseling Dialogue System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **A modular psychological counseling system with dual-knowledge-base RAG and three-layer memory**

[ä¸­æ–‡æ–‡æ¡£](README_zh.md) 

---

## ğŸ“ Overview

This repository contains the implementation of our paper:

**"Intelligent Psychological Counseling Dialogue System Based on Dual-Knowledge-Base RAG and Three-Layer Memory"**

The system addresses key challenges in AI-powered mental health support:
- **Professional accuracy** through Retrieval-Augmented Generation (RAG)
- **Long-term personalization** with a three-layer memory system
- **Privacy protection** via local model deployment options

### Key Features

ğŸ”¬ **Dual Knowledge Base Architecture**
- Separated professional psychology knowledge (CBT, anxiety management, etc.)
- Individual user profile knowledge base
- Differentiated retrieval strategies for balanced professionalism and personalization

ğŸ§  **Three-Layer Memory System**
- **Working Memory**: Current session context (last 10 turns)
- **Short-term Memory**: Session-level summaries (last 20 sessions)
- **Long-term Memory**: Persistent user profiles and cross-session trends

ğŸ› ï¸ **Modular & Flexible Design**
- Support for both local models (Qwen2-7B) and API models (GPT-4)
- Easy configuration via YAML files
- Independent module testing and replacement

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/Wang-qishen/psychological_counseling_system.git
cd psychological_counseling_system

# Install dependencies
pip install -r requirements.txt

# Download embedding model (first time only)
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
```

### Basic Usage

```python
from dialogue import create_dialogue_manager_from_config
import yaml

# Load configuration
with open('configs/config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Create dialogue manager
manager = create_dialogue_manager_from_config(config)

# Start a conversation
user_id = "user001"
session_id = manager.start_session(user_id)

# Chat
response = manager.chat(
    user_id=user_id,
    session_id=session_id,
    user_message="I've been feeling very anxious lately..."
)

print(response)
```

### Run Evaluation Experiments

```bash
# Quick test (5 minutes)
python evaluation/scripts/run_quick_test.py

# Full comparison experiment (reproduces paper results)
python examples/comparison_experiment.py
```

See [Quick Start Guide](docs/quickstart.md) for more details.

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Dialogue Manager                            â”‚
â”‚  Orchestrates modules Â· Context building Â· Prompt engineering    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                    â”‚
       â–¼                   â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Layer  â”‚   â”‚   RAG Layer       â”‚   â”‚   Memory Layer     â”‚
â”‚             â”‚   â”‚                   â”‚   â”‚                    â”‚
â”‚ â€¢ Qwen2-7B  â”‚   â”‚ â€¢ Professional KB â”‚   â”‚ â€¢ Working Memory   â”‚
â”‚ â€¢ GPT-4     â”‚   â”‚ â€¢ Personal KB     â”‚   â”‚ â€¢ Short-term Memoryâ”‚
â”‚             â”‚   â”‚                   â”‚   â”‚ â€¢ Long-term Memory â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [Architecture Documentation](docs/architecture.md) for detailed design.

---

## ğŸ“‚ Project Structure

```
psychological_counseling_system/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ INSTALLATION.md              # Detailed installation guide
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ configs/                     # Configuration files
â”‚   â””â”€â”€ config.yaml              # Main configuration
â”‚
â”œâ”€â”€ dialogue/                    # Dialogue management module
â”‚   â””â”€â”€ manager.py               # Core dialogue manager
â”‚
â”œâ”€â”€ llm/                         # LLM layer (local + API)
â”‚   â”œâ”€â”€ local_llm.py             # Local model (llama.cpp)
â”‚   â””â”€â”€ openai_llm.py            # OpenAI API
â”‚
â”œâ”€â”€ knowledge/                   # RAG layer
â”‚   â”œâ”€â”€ chroma_kb.py             # ChromaDB knowledge base
â”‚   â””â”€â”€ rag_manager.py           # RAG manager
â”‚
â”œâ”€â”€ memory/                      # Memory system
â”‚   â”œâ”€â”€ models.py                # Memory data models
â”‚   â”œâ”€â”€ storage.py               # Storage backend
â”‚   â””â”€â”€ manager.py               # Memory manager
â”‚
â”œâ”€â”€ evaluation/                  # Evaluation framework
â”‚   â”œâ”€â”€ configs/                 # Evaluation configs
â”‚   â”œâ”€â”€ datasets/                # Dataset loaders
â”‚   â”œâ”€â”€ metrics/                 # Evaluation metrics
â”‚   â””â”€â”€ scripts/                 # Evaluation scripts
â”‚
â”œâ”€â”€ examples/                    # Usage examples
â”‚   â”œâ”€â”€ basic_rag_chat.py        # Basic RAG chat
â”‚   â”œâ”€â”€ comparison_experiment.py # Comparison experiment
â”‚   â””â”€â”€ evaluation_examples.py   # Evaluation examples
â”‚
â”œâ”€â”€ experiments/                 # Experiment results
â”‚   â”œâ”€â”€ detailed_comparison.md   # Comparison results
â”‚   â””â”€â”€ response_examples.md     # Response examples
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ architecture.md          # System architecture
â”‚   â”œâ”€â”€ quickstart.md            # Quick start guide
â”‚   â”œâ”€â”€ configuration.md         # Configuration guide
â”‚   â”œâ”€â”€ evaluation.md            # Evaluation guide
â”‚   â””â”€â”€ examples.md              # Usage examples
â”‚
â””â”€â”€ models/                      # Model storage
    â””â”€â”€ README.md                # Model download guide
```

---

## ğŸ“š Documentation

- [Installation Guide](INSTALLATION.md) - Detailed setup instructions
- [Quick Start](docs/quickstart.md) - Get started in 5 minutes
- [Architecture](docs/architecture.md) - System design and components
- [Configuration](docs/configuration.md) - Configuration parameters
- [Evaluation Guide](docs/evaluation.md) - How to reproduce experiments
- [Usage Examples](docs/examples.md) - Code examples

---

## ğŸ”¬ Reproducing Paper Results

Our paper presents three main experiments:

### 1. Comparison Experiment

Compare three configurations: Bare LLM, LLM+RAG, and Full System

```bash
python examples/comparison_experiment.py
```

Results will be saved to `experiments/` directory.

### 2. Case Study

Run specific counseling scenarios:

```bash
python examples/case_study.py --scenario anxiety
```

### 3. User Experience Evaluation

See [Evaluation Guide](docs/evaluation.md) for details.

---

## ğŸ› ï¸ Configuration

The system is highly configurable via `configs/config.yaml`:

```yaml
llm:
  backend: 'local'  # 'local' or 'api'
  local:
    model_path: 'models/qwen2-7b-instruct-q4_k_m.gguf'
  api:
    provider: 'openai'
    model: 'gpt-4o-mini'

rag:
  retrieval:
    top_k: 5
    score_threshold: 0.5

memory:
  layers:
    session:
      max_turns: 10
    profile:
      auto_update: true
```

See [Configuration Guide](docs/configuration.md) for all options.

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

